{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "![iteso](https://upload.wikimedia.org/wikipedia/en/5/5f/Western_Institute_of_Technology_and_Higher_Education_logo.png)\n",
    "\n",
    "###  InstitutoTecnológico y de Estudios Superiores de Occidente ###\n",
    "###  Maestría Ciencia de Datos  ###\n",
    "###  Modelado Predictivo ###\n",
    "# Tarea 2: PCA vs LDA #\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "* * *\n",
    "\n",
    "Estudiante: Daniel Nuño <br>\n",
    "Profesor: Dr. Riemann Ruiz Cruz <br>\n",
    "Fecha entrega: 14 de septiembre 2022<br>\n",
    "\n",
    "* * *\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this exercise, the dataset that will be used is the well-known “digits” dataset, which is already included in the sklearn library [(sklearn.datasets.load_digits — scikit-learn 1.1.2 documentation)](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html). This dataset is used to test classification models because the output variable contains ten valid classes which correspond to each digit between 0 and 9. The dataset is a copy of the test set of the UCI ML hand-written digits datasets :\n",
    "\n",
    "[https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits](https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits)\n",
    "\n",
    "*We used preprocessing programs made available by NIST to extract normalized bitmaps of handwritten digits from a preprinted form. From a total of 43 people, 30 contributed to the training set and different 13 to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of 4x4 and the number of on pixels are counted in each block. This generates an input matrix of 8x8 where each element is an integer in the range 0..16. This reduces dimensionality and gives invariance to small distortions.*\n",
    "\n",
    "- *All input attributes are integers in the range 0..16.*\n",
    "- *The last attribute is the class code 0..9*\n",
    "\n",
    "\n",
    "Using the data set mentioned, develop the following points:\n",
    "1. Create two subsets of data, where the first one will be used for the training process and the second one for the testing process. It is important that the same data subsets are used for all subsequent models.\n",
    "2. Train a logistic regression model to estimate the feature “target” using all the pixels in the image as input variables. Get the accuracy values or another metric (precision, recall, …) to evaluate the model's performance in training and testing.\n",
    "3. Considering the data set obtained in point 1, perform the dimension reduction using the PCA method. With the variables resulting from the reduction process, train a new logistic regression model and calculate the same metrics used in point 2.\n",
    "4. Considering the data set used in point 1 again, perform a variable reduction by LDA transformation. With the variables resulting from the transformation process, train a new logistic regression wich must be evaluated with the same metrics as the previous models.\n",
    "5. Considering the data set used in point 1 again; train a LDA model and evaluate the model with the same metrics.\n",
    "6. As a result of the previous steps, we have four different models to solve the problem proposed. Make a table with the metrics of each model to make a comparison of the models.\n",
    "\n",
    "## Development\n",
    "\n",
    "### Create two subsets of data, where the first one will be used for the training process and the second one for the testing process. It is important that the same data subsets are used for all subsequent models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = load_digits(return_X_y = True)\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a logistic regression model to estimate the feature “target” using all the pixels in the image as input variables. Get the accuracy values or another metric (precision, recall, …) to evaluate the model's performance in training and testing.\n",
    "\n",
    "Using the LogisticRgression function from sklear.\n",
    "\n",
    "> *In the multiclass case, the training algorithm uses the one-vs-rest (OvR) scheme if the ‘multi_class’ option is set to ‘ovr’, and uses the cross-entropy loss if the ‘multi_class’ option is set to ‘multinomial’.*\n",
    "\n",
    "> *If the option chosen is ‘ovr’, then a binary problem is fit for each label. For ‘multinomial’ the loss minimised is the multinomial loss fit across the entire probability distribution, even when the data is binary. ‘multinomial’ is unavailable when solver=’liblinear’. ‘auto’ selects ‘ovr’ if the data is binary, or if solver=’liblinear’, and otherwise selects ‘multinomial’.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score : 0.991 (ovr)\n",
      "test score : 0.970 (ovr)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(solver = 'sag', multi_class='ovr').fit(X_train, y_train)\n",
    "print(\"training score : %.3f (%s)\" % (clf.score(X_train, y_train), 'ovr'))\n",
    "print(\"test score : %.3f (%s)\" % (clf.score(X_test, y_test), 'ovr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considering the data set obtained in point 1, perform the dimension reduction using the PCA method. With the variables resulting from the reduction process, train a new logistic regression model and calculate the same metrics used in point 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14411041 0.27974295 0.39907761 0.48504358 0.54453354 0.59340297\n",
      " 0.63754404 0.6738149  0.70782563 0.73826034 0.76207807 0.78428237\n",
      " 0.80300624 0.82092233 0.83614756 0.85024667 0.86336471 0.8755268\n",
      " 0.88552272 0.89486969 0.90397009 0.91188756 0.91945312 0.92653139\n",
      " 0.93342653 0.93923663 0.94485927 0.94998684 0.95493708 0.95929918\n",
      " 0.96303541 0.9664767  0.9698009  0.97300449 0.97600818 0.97894754\n",
      " 0.98159697 0.98390353 0.9861197  0.98816846 0.99004884 0.99162734\n",
      " 0.99313858 0.99462228 0.99580284 0.99689066 0.99783568 0.99864156\n",
      " 0.99920862 0.99957922 0.99975784 0.99984919 0.99989926 0.99994486\n",
      " 0.99998205 0.9999934  0.99999776 0.9999989  0.99999964 1.\n",
      " 1.         1.         1.         1.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22011e933a0>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "pca = PCA()\n",
    "pca = pca.fit(X_train)\n",
    "pca.explained_variance_ratio_\n",
    "print(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.plot(range(64), np.cumsum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the 10 to 30 principal components will represent the majority of variance from the input data. More than that the change is marginal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_train = pca.transform(X_train)\n",
    "X_pca_train = X_pca_train[:, :30]\n",
    "X_pca_test = pca.transform(X_test)\n",
    "X_pca_test = X_pca_test[:, :30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score PCA: 0.974 \n",
      "test score PCA: 0.970 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf_pca = LogisticRegression(solver = 'sag', multi_class='ovr').fit(X_pca_train, y_train)\n",
    "print(\"training score PCA: %.3f \" % (clf_pca.score(X_pca_train, y_train)))\n",
    "print(\"test score PCA: %.3f \" % (clf_pca.score(X_pca_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considering the data set used in point 1 again, perform a variable reduction by LDA transformation. With the variables resulting from the transformation process, train a new logistic regression wich must be evaluated with the same metrics as the previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26660995 0.45236365 0.63080783 0.75623888 0.84302717 0.91165359\n",
      " 0.95098847 0.97997637 1.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '% explained variance')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXOUlEQVR4nO3de7hddZ3f8ffHIFVQQSWjlhDDTBkd6gBiRBQGRQuCVMFLZ1DUp6hQWhCvY7Gto87oU+qtjhaNqDjiqEgd8IkQBToq1jJIAnJHnBQzEsEBvADilOu3f6x1cHOyzsnKSdbZO8n79Tzn2Xv91vrt9T2bhE/W5fdbqSokSZruYeMuQJI0mQwISVInA0KS1MmAkCR1MiAkSZ22GXcBm9JOO+1US5YsGXcZkrTZuPTSS2+rqoVd67aogFiyZAmrVq0adxmStNlI8g8zrfMUkySpkwEhSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKnTFjWSemMsOencedvXmpMPm7d9SdJceQQhSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKnToAGR5JAk1ydZneSkjvVHJbmy/bkoyZ4j69YkuSrJ5Ul8jqgkzbPBRlInWQCcAhwErAVWJlleVdeObPZj4LlV9cskhwKnAs8aWX9gVd02VI2SpJkNeQSxD7C6qm6oqnuAM4DDRzeoqouq6pft4sXAogHrkSRtgCEDYmfgxpHltW3bTF4PfGNkuYDzk1ya5NgB6pMkzWLIyfrS0VadGyYH0gTE/iPN+1XVTUl+B7ggyQ+r6rsdfY8FjgVYvHjxxlctSQKGPYJYC+wysrwIuGn6Rkn2AD4DHF5VP59qr6qb2tdbgLNpTlmto6pOraqlVbV04cKFm7B8Sdq6DRkQK4HdkuyaZFvgSGD56AZJFgNnAa+pqh+NtG+f5NFT74GDgasHrFWSNM1gp5iq6r4kJwDnAQuA06rqmiTHteuXAX8GPB74RBKA+6pqKfAE4Oy2bRvgS1X1zaFqlSSta9AHBlXVCmDFtLZlI+/fALyho98NwJ7T2yVJ88eR1JKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI69Q6IJNsPWYgkabKsNyCSPCfJtcB17fKeST4xeGWSpLHqcwTx34EXAj8HqKorgAP6fHiSQ5Jcn2R1kpM61h+V5Mr256Ike/btK0kaVq9TTFV147Sm+9fXJ8kC4BTgUGB34JVJdp+22Y+B51bVHsBfAKduQF9J0oD6BMSNSZ4DVJJtk7yd9nTTeuwDrK6qG6rqHuAM4PDRDarqoqr6Zbt4MbCob19J0rD6BMRxwPHAzsBaYK92eX12BkaPPNa2bTN5PfCNDe2b5Ngkq5KsuvXWW3uUJUnqY5v1bVBVtwFHzeGz0/VxnRsmB9IExP4b2reqTqU9NbV06dLObSRJG67PXUyfT7LjyPJjk5zW47PXAruMLC8Cbur4/D2AzwCHV9XPN6SvJGk4fU4x7VFVv5paaK8ZPL1Hv5XAbkl2TbItcCSwfHSDJIuBs4DXVNWPNqSvJGlY6z3FBDwsyWOnLiYneVyfflV1X5ITgPOABcBpVXVNkuPa9cuAPwMeD3wiCcB9VbV0pr5z+P0kSXPUJyA+DFyU5Kvt8r8B3t/nw6tqBbBiWtuykfdvAN7Qt68kaf70ORI4PcmlwIE0F49fVlXXDl6ZJGms+hxBAPwQ+OXU9kkWV9VPBqtKkjR26w2IJG8E3g38I80I6tDccrrHsKVJksapzxHEm4CnjNyCKknaCvSaagO4fehCJEmTpc8RxA3Ad5KcC9w91VhVHxmsKknS2PUJiJ+0P9u2PxrQkpPOndf9rTn5sHndn6TNR5/bXN87H4VIkiZLn7uYFgLvAP4l8Iip9qp6/oB1SZLGrM9F6i/SjIPYFXgvsIZmriRJ0hasT0A8vqo+C9xbVRdW1euAfQeuS5I0Zn0uUt/bvt6c5DCaabcXzbK9thBeMJe2bn0C4n1JdgDeBnwceAzwlkGrkiSNXZ+7mM5p395OM2GfJGkrMGNAJHlHVX0gycfpeNxnVZ04aGWSpLGa7QjiuvZ11XwUIkmaLDMGRFV9PckC4GlV9afzWJMkaQLMeptrVd0PPGOeapEkTZA+dzH9IMly4H8Cd001VtVZg1UlSRq7PgHxOODnwOjUGgUYEJK0Betzm+vR81GIJGmy9Jms7xHA61l3sr7XDViXJGnM+szF9AXgicALgQtpptm4c8iiJEnj1ycg/kVVvQu4q6o+DxwG/OGwZUmSxq1PQExN1verJE8DdgCWDFaRJGki9LmL6dQkjwXeBSwHHtW+lyRtwfoExOfaAXMXAr87cD2SpAnR5xTTj5OcmuQFSTJ4RZKkidAnIJ4C/C/geGBNkv+RZP9hy5Ikjdt6A6Kq/qmqzqyqlwF70Tww6MKhC5MkjVefIwiSPDfJJ4DLaAbL/XHPfockuT7J6iQndax/apK/S3J3krdPW7cmyVVJLk/ilOOSNM/6jKT+MXA5cCbwp1V11+w9Huy3ADgFOAhYC6xMsryqrh3Z7BfAicARM3zMgVV1W5/9SZI2rT53Me1ZVXfM4bP3AVZX1Q0ASc4ADgceDIiqugW4JYlPq5ekCdPnGsRcwgFgZ+DGkeW1bVtfBZyf5NIkx860UZJjk6xKsurWW2+dY6mSpOl6XYOYo65bYtd5tvUs9quqvYFDgeOTHNC1UVWdWlVLq2rpwoUL51KnJKnDkAGxFthlZHkRcFPfzlV1U/t6C3A2zSkrSdI8mfEaRJK3ztaxqj6yns9eCeyWZFfgp8CRwKv6FJVke+BhVXVn+/5g4M/79JUkbRqzXaR+dPv6FOCZNPMwAbwY+O76Priq7ktyAnAesAA4raquSXJcu35ZkicCq2jGVjyQ5M3A7sBOwNntwO1tgC9V1Tc38HeTJG2EGQOiqt4LkOR8YO+qurNdfg/N86nXq6pWACumtS0bef8zmlNP090B7NlnH5KkYfS5BrEYuGdk+R6c7luStnh9xkF8Abgkydk0dyG9FDh90KokSWO33oCoqvcn+QbwR23T0VX1g2HLkiSNW9/bXLcD7qiqvwTWtncmSZK2YOsNiCTvBv4j8M626eHAXw9ZlCRp/PocQbwUeAlwFzw4gO3Rs/aQJG32+gTEPVVVtNNktAPXJElbuD4BcWaSTwE7JjmG5ulynx62LEnSuPW5i+lDSQ6iGbz2FODPquqCwSuTJI1Vn3EQtIFgKEjSVqTPXUwvS/L3SW5PckeSO5PM9RkRkqTNRJ8jiA8AL66q64YuRpI0OfpcpP5Hw0GStj59jiBWJfkK8DXg7qnGqjprqKKk6ZacdO687WvNyT4iXYJ+AfEY4Dc0D+2ZUoABIUlbsD63uR49H4VIkibLbI8cfUdVfSDJx2lHUY+qqhMHrUySNFazHUFMXZheNR+FSJImy2yPHP16+/r5+StHkjQp1nsNIslCmum+dwceMdVeVc8fsC5J0pj1GQfxRZrTTbsC7wXWACsHrEmSNAH6BMTjq+qzwL1VdWFVvQ7Yd+C6JElj1mccxL3t681JDgNuAhYNV5IkaRL0CYj3JdkBeBvwcZqBc28ZtCpJ0tj1GSh3Tvv2duDAYcuRJE2K2QbKdQ6Qm+JAOUnass12BOEAOUnais02UO4hA+SSPKZprjsHr0qSNHZ9nii3NMlVwJXA1UmuSPKM4UuTJI1Tn7uYTgP+Q1X9b4Ak+wOfA/YYsjBJ0nj1GSh351Q4AFTV94Bep5mSHJLk+iSrk5zUsf6pSf4uyd1J3r4hfSVJw+pzBHFJkk8BX6a5q+lPgO8k2Rugqi7r6pRkAXAKcBCwFliZZHlVXTuy2S+AE4Ej5tBXkjSgPgGxV/v67mntz6EJjJkm7dsHWF1VNwAkOQM4HHjwf/JVdQtwSztCe4P6SpKG1Weg3FwHx+0M3DiyvBZ41qbum+RY4FiAxYsXb3iVkqROfe5i+kI71cbU8pOT/G2Pz05H24wD7+bat6pOraqlVbV04cKFPT9ekrQ+fS5Sfw/4fpIXJTkGuAD4aI9+a4FdRpYX0Uz018fG9JUkbQJ9TjF9Ksk1wLeB24CnV9XPenz2SmC3JLsCPwWOBF7Vs66N6StJ2gT6PFHuNcC7gNfSjH1YkeToqrpitn5VdV+SE4DzgAXAaVV1TZLj2vXLkjyRZkqPxwAPJHkzsHtV3dHVd86/pSRpg/W5i+nlwP7tHUdfTnI28Hl+e3fTjKpqBbBiWtuykfc/Y4ZnS3T1lSTNnz6nmI4ASLJ9Vd1VVZck2WfwyiRJY9XnLqZnJ7mW5rnUJNmTfhepJUmbsT53MX0UeCHwc4D22sMBA9YkSZoAfQKCqrpxWtP9A9QiSZogfS5S35jkOUAl2ZZm7qTrhi1LmkxLTjp3Xve35uTps9BI86fPEcRxwPE001+spbl76fgBa5IkTYA+dzHdBhw1D7VIkiZIr2sQkqStjwEhSepkQEiSOvUOiCT7JvlWkv+T5IgBa5IkTYAZL1IneeK0WVvfCryE5lkNFwFfG7Y0SdI4zXYX07IklwIfrKr/B/yKZsrtB4A75qE2SdIYzXiKqZ2k73LgnHbK7zfThMN2wBHDlyZJGqdZr0FU1ddp5mHaETgLuL6qPlZVt85DbZKkMZoxIJK8JMn3gG8BV9M81e2lSb6c5Pfmq0BJ0njMdg3ifcCzgUcCK6pqH+CtSXYD3k8TGJKkLdRsAXE7TQg8ErhlqrGq/h7DQZK2eLMFxEuBVwL30ty9JGmCzOfMss4qu3WaMSDaSfo+Po+1SJImiFNtSJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkToMGRJJDklyfZHWSkzrWJ8nH2vVXJtl7ZN2aJFcluTzJqiHrlCSta7bJ+jZKkgXAKcBBwFpgZZLlVXXtyGaHAru1P88CPtm+TjmwnRNKkjTPhjyC2AdYXVU3VNU9wBnA4dO2ORw4vRoXAzsmedKANUmSehoyIHYGbhxZXtu29d2mgPOTXJrk2Jl2kuTYJKuSrLr1Vp+EKkmbypABkY622oBt9quqvWlOQx2f5ICunVTVqVW1tKqWLly4cO7VSpIeYsiAWAvsMrK8CLip7zZVNfV6C3A2zSkrSdI8GTIgVgK7Jdk1ybY0jyldPm2b5cBr27uZ9gVur6qbk2yf5NEASbYHDgauHrBWSdI0g93FVFX3JTkBOA9YAJxWVdckOa5dvwxYAbwIWA38Bji67f4E4OwkUzV+qaq+OVStkqR1DRYQAFW1giYERtuWjbwv4PiOfjcAew5ZmyRpdo6kliR1MiAkSZ0GPcUkacu35KRz53V/a04+bF73tzXzCEKS1MmAkCR1MiAkSZ0MCElSJwNCktTJgJAkdTIgJEmdHAchaYvhmIxNyyMISVInA0KS1MmAkCR1MiAkSZ0MCElSJwNCktTJ21wlaRPbUm639QhCktTJgJAkdTIgJEmdDAhJUicDQpLUyYCQJHUyICRJnQwISVInA0KS1MmAkCR1MiAkSZ0MCElSp0EDIskhSa5PsjrJSR3rk+Rj7fork+zdt68kaViDBUSSBcApwKHA7sArk+w+bbNDgd3an2OBT25AX0nSgIY8gtgHWF1VN1TVPcAZwOHTtjkcOL0aFwM7JnlSz76SpAEN+TyInYEbR5bXAs/qsc3OPfsCkORYmqMPgF8nuX4jap6LnYDbNqRD/ttAlczBQLVs8HcCk/O9+J2sy++k2wC1jOM7efJMK4YMiHS0Vc9t+vRtGqtOBU7dsNI2nSSrqmrpuPY/ifxO1uV3si6/k3VN2ncyZECsBXYZWV4E3NRzm2179JUkDWjIaxArgd2S7JpkW+BIYPm0bZYDr23vZtoXuL2qbu7ZV5I0oMGOIKrqviQnAOcBC4DTquqaJMe165cBK4AXAauB3wBHz9Z3qFo30thOb00wv5N1+Z2sy+9kXRP1naSq89S+JGkr50hqSVInA0KS1MmAmCOnAnmoJLsk+XaS65Jck+RN465pUiRZkOQHSc4Zdy2TIsmOSb6a5Iftn5lnj7umcUvylvbvztVJvpzkEeOuyYCYA6cC6XQf8Laq+gNgX+B4v5MHvQm4btxFTJi/BL5ZVU8F9mQr/36S7AycCCytqqfR3Jxz5HirMiDmyqlApqmqm6vqsvb9nTR/4Xceb1Xjl2QRcBjwmXHXMimSPAY4APgsQFXdU1W/GmtRk2Eb4JFJtgG2YwLGfhkQczPTFCECkiwBng58f8ylTIKPAu8AHhhzHZPkd4Fbgc+1p94+k2T7cRc1TlX1U+BDwE+Am2nGhJ0/3qoMiLnqPRXI1ibJo4C/Ad5cVXeMu55xSvKvgVuq6tJx1zJhtgH2Bj5ZVU8H7gK26ut4SR5LcxZiV+CfA9snefV4qzIg5qrPNCJbnSQPpwmHL1bVWeOuZwLsB7wkyRqa05DPT/LX4y1pIqwF1lbV1BHmV2kCY2v2r4AfV9WtVXUvcBbwnDHXZEDMkVOBTJMkNOeUr6uqj4y7nklQVe+sqkVVtYTmz8i3qmrs/yoct6r6GXBjkqe0TS8Arh1jSZPgJ8C+SbZr/y69gAm4cD/kZH1brM1sKpD5sh/wGuCqJJe3bf+pqlaMryRNsDcCX2z/gXUD7TQ7W6uq+n6SrwKX0dwR+AMmYNoNp9qQJHXyFJMkqZMBIUnqZEBIkjoZEJKkTgaEJKmTAaHNVpJK8uGR5bcnec887n9pko/N1/5mqeM9Sd4+7jq05TEgtDm7G3hZkp3GsfOqWlVVJ45j39J8MCC0ObuPZjDRW6avSPJXSV4xsvzr9vV5SS5McmaSHyU5OclRSS5JclWS3+v4rO2TnJZkZTu53OEjn3VO+35hkguSXJbkU0n+YSq4kry6/fzL23ULpmpK8v4kVyS5OMkTkuyQZE2Sh7XbbJfkxiQPT3JMW8MVSf4myXYdtX4nydL2/U7tNB9Tz6T4YNv/yiT/rm1/UpLvtrVdneSPNuq/iLYoBoQ2d6cARyXZYQP67EnzjIY/pBn9/ftVtQ/NlNxv7Nj+P9NMk/FM4EDggx2zj7673WZv4GxgMUCSPwD+BNivqvYC7geOavtsD1xcVXsC3wWOqarbgSuA57bbvBg4b2p+nqp6Zrv9dcDrN+B3fj3NDKHPBJ4JHJNkV+BV7efv1X4vl2/AZ2oL51Qb2qxV1R1JTqd52Mo/9ey2sqpuBkjyf4GpaZWvogmA6Q6mmXRv6jz/I2gDYMT+wEvbmr6Z5Jdt+wuAZwArmyl2eCRwS7vuHmDqKXOXAge1779CEyrfppnD6RNt+9OSvA/YEXgUzVQvfR0M7DFyVLUDsBvNvGKntRMtfq2qLt+Az9QWzoDQluCjNHPYfG6k7T7aI+R28rNtR9bdPfL+gZHlB+j+OxHg5VV1/UMakydM26ZLgM9X1Ts71t1bv53r5v6RfS8H/muSx9GEy7fa9r8CjqiqK5L8W+B5HZ/54O9NE2SjdbyxqtYJlSQH0DzU6AtJPlhVp8/wu2gr4ykmbfaq6hfAmTz0lMsamv+5QjPP/sM3YhfnAW9sg4YkT+/Y5nvAH7frDwYe27b/LfCKJL/TrntckifPtrOq+jVwCc1jOc+pqvvbVY8Gbm7/tX/UDN3X8Nvf+xUj7ecB/77tS5Lfb6+tPJnmmRWfppmNd2ufdlsjDAhtKT4MjN7N9GnguUkuAZ5F81CaufoLmoC5MsnV7fJ07wUOTnIZzbPKbwburKprgf8CnJ/kSuAC4Ek99vkV4NXt65R30Tyl7wLghzP0+xBNEFzEQ7+Pz9BMqX1Z+zt8iuaI5XnA5Ul+ALycJpQkwNlcpU0iyT8D7m+ngn82zdPS9hpzWdJG8RqEtGksBs5sb0+9BzhmzPVIG80jCElSJ69BSJI6GRCSpE4GhCSpkwEhSepkQEiSOv1/MCLVCktgpsgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda_model = LinearDiscriminantAnalysis(store_covariance=True)\n",
    "lda_model = lda_model.fit(X_train, y_train)\n",
    "\n",
    "print(np.cumsum(lda_model.explained_variance_ratio_))\n",
    "plt.bar(np.arange(len(lda_model.explained_variance_ratio_)),lda_model.explained_variance_ratio_)\n",
    "plt.xlabel('Num eigenvalues')\n",
    "plt.ylabel('% explained variance')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lda_train = lda_model.transform(X_train)\n",
    "X_lda_test = lda_model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\nuno\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score LDA Log: 0.967 \n",
      "test score LDA Log: 0.963 \n"
     ]
    }
   ],
   "source": [
    "clf_lda = LogisticRegression(solver = 'sag', multi_class='ovr').fit(X_lda_train, y_train)\n",
    "print(\"training score LDA Log: %.3f \" % (clf_lda.score(X_lda_train, y_train)))\n",
    "print(\"test score LDA Log: %.3f \" % (clf_lda.score(X_lda_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considering the data set used in point 1 again; train a LDA model and evaluate the model with the same metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score LDA: 0.961 \n",
      "test score LDA: 0.963 \n"
     ]
    }
   ],
   "source": [
    "print(\"training score LDA: %.3f \" % (lda_model.score(X_train, y_train)))\n",
    "print(\"test score LDA: %.3f \" % (lda_model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As a result of the previous steps, we have four different models to solve the problem proposed. Make a table with the metrics of each model to make a comparison of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score Train</th>\n",
       "      <th>Score Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Original Log</td>\n",
       "      <td>0.991249</td>\n",
       "      <td>0.970370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA Log</td>\n",
       "      <td>0.973747</td>\n",
       "      <td>0.970370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LDA Log</td>\n",
       "      <td>0.966587</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.961018</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Score Train  Score Test\n",
       "0  Original Log     0.991249    0.970370\n",
       "1       PCA Log     0.973747    0.970370\n",
       "2       LDA Log     0.966587    0.962963\n",
       "3           LDA     0.961018    0.962963"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "results = {'Model': [\"Original Log\", \"PCA Log\", \"LDA Log\", \"LDA\"],\n",
    "           'Score Train': [clf.score(X_train, y_train), clf_pca.score(X_pca_train, y_train), clf_lda.score(X_lda_train, y_train), lda_model.score(X_train, y_train)],\n",
    "           'Score Test': [clf.score(X_test, y_test), clf_pca.score(X_pca_test, y_test), clf_lda.score(X_lda_test, y_test), lda_model.score(X_test, y_test)]}\n",
    "\n",
    "results = pd.DataFrame(data=results)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "The original model has the best performance within trainning dataset. However, using pca and lda the acurracy is still pretty close in the test dataset and the difference between train and test scores are closer. Like not less overtrained."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "50a2db19f1a5826b7a7c49721eefb839e2f4ea4b5c5d5ee89308ab778aa63f0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
